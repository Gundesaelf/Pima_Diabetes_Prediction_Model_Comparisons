ğŸ§¬ Diabetes Prediction with Naive Bayes, Logistic Regression, and Random Forest ğŸ“Œ Project Overview This project predicts diabetes diagnoses using the Pima Indians Diabetes Dataset from Kaggle. The focus is on data cleaning, handling missing values, and building a prediction model using Gaussian Naive Bayes. The goal: to create a simple, interpretable, and reasonably accurate medical prediction baseline.

1ï¸âƒ£ Tools & Libraries Used ğŸ”§ Programming & Modeling Tools: Python (VS Code) â€“ Model development, data preprocessing, evaluation

ğŸ“¦ Python Libraries: pandas â€“ Data loading and manipulation

numpy â€“ Numerical operations and imputation

scikit-learn â€“ Model building, evaluation, and train/test splitting

colorama â€“ Terminal output formatting (for better readability in CLI)

2ï¸âƒ£ Data Wrangling Process The dataset originally contained zero-values in some columns. A preprocessing pipeline was developed to handle this:

âœ” Initial Overview â€“ Prints the dataset shape and first five rows âœ” Zero Replacement â€“ Replaces 0 values in key medical columns with NaN âœ” Missing Value Imputation â€“ Fills NaN values using column-wise mean âœ” Feature Selection â€“ Drops Age to see how the model performs without it âœ” Train-Test Split â€“ Splits data into 50% train / 50% test using random_state=43

3ï¸âƒ£ Machine Learning Models ğŸ¤– Models Used: Gaussian Naive Bayes, Logistic Regressin, and Random Forest

ğŸ” Evaluation Metrics: Accuracy

Precision

Recall

F1 Score

A detailed classification report is printed with color-coded terminal output for clarity.


ğŸ”— Connect with me https://www.linkedin.com/in/chris-gundes
